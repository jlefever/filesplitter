{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import sqlite3\n",
    "import math\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.cluster import DBSCAN\n",
    "from ordered_set import OrderedSet as oset\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from filesplitter import db, subjects, naming\n",
    "from filesplitter.clustering import cluster_dataset, to_name_cluster_labels\n",
    "from filesplitter.loading import load_dataset\n",
    "from filesplitter.validate import validate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define some basic notation.\n",
    "\n",
    "- Let $D$ be the set of documents (identifiers) and let $T$ be the set of terms.\n",
    "\n",
    "- Let $S \\subseteq T \\times D$ be the set of term-document occurrences (or _sample points_.) If `allow_dup_docs = True`, then $S$ is a multi-set.\n",
    "\n",
    "Next, define some useful subsets.\n",
    "\n",
    "- Let $S_i = \\{s : s = (t,d) \\in S \\text{ and } t=t_i\\}$ be the subset of occurrences that contain term $t_i$.\n",
    "\n",
    "- Let $S_j = \\{s : s = (t,d) \\in S \\text{ and } d=d_j\\}$ be the subset of occurrences that contain document $d_j$.\n",
    "\n",
    "- Let $S_{ij} = \\{s : s = (t,d) \\in S \\text{ and } t=t_i \\text{ and } d=d_j\\}$ be the subset of occurrences that contain both term $t_i$ and document $d_j$.\n",
    "\n",
    "And some useful shorthand for refering the size of these subsets.\n",
    "\n",
    "- Let $c = |S|$ be the number of term-document pairs.\n",
    "\n",
    "- Let $c_i = |S_i|$ be the number of documents that contain term $t_i$.\n",
    "\n",
    "- Let $c_j = |S_j|$ be the number of terms that are contained within document $d_j$.\n",
    "\n",
    "- Let $c_{ij} = |S_{ij}|$ be the number of times term $t_i$ is used by document $d_j$.\n",
    "\n",
    "Now define some random variables.\n",
    "\n",
    "- Let $X_i(s)$ for some $s = (t, d) \\in S$ be the indicator random variable $\\mathbf{1}_{S_i}$.\n",
    "\n",
    "- Let $Y_j(s)$ for some $s = (t, d) \\in S$ be the indicator random variable $\\mathbf{1}_{S_j}$.\n",
    "\n",
    "If we assume each sample point $s \\in S$ is equiprobable, we can find these joint probability distributions.\n",
    "\n",
    "- $P(X_i = 1; Y_j = 1) = p_{ij}(1,1) = c_{ij}/c$\n",
    "\n",
    "- $P(X_i = 1; Y_j = 0) = p_{ij}(1,0) = (c_i - c_{ij}) / c$\n",
    "\n",
    "- $P(X_i = 0; Y_j = 1) = p_{ij}(0,1) = (c_j - c_{ij}) / c$\n",
    "\n",
    "- $P(X_i = 0; Y_j = 0) = p_{ij}(0,0) = (c + c_{ij} - c_i - c_j) / c$\n",
    "\n",
    "And then the marginals.\n",
    "\n",
    "- $P(X_i = 1) = p_{i}(1) = c_i / c$\n",
    "\n",
    "- $P(X_i = 0) = p_{i}(0) = 1 - c_i / c = (c - c_i) / c$\n",
    "\n",
    "- $P(Y_j = 1) = p_{j}(1) = c_j / c$\n",
    "\n",
    "- $P(Y_j = 0) = p_{j}(0) = 1 - c_j / c = (c - c_j) / c$\n",
    "\n",
    "Now we can derive the mutual information between any $X_i$ and $Y_j$.\n",
    "\n",
    "\\begin{align*}\n",
    "I(X_i;Y_j)\n",
    "&=\n",
    "\\sum_{y \\in \\{0,1\\}}\\sum_{x \\in \\{0,1\\}}\n",
    "P(X_i = x; Y_j = y)\n",
    "\\log{\\left(\\frac{P(X_i = x; Y_j = y)}{P(X_i = x)P(Y_j = y)}\\right)} \\\\\n",
    "\n",
    "&=\n",
    "\\sum_{y \\in \\{0,1\\}}\\sum_{x \\in \\{0,1\\}}\n",
    "p_{ij}(x,y)\n",
    "\\log{\\left(\\frac{p_{ij}(x,y)}{p_i(x)p_j(y)}\\right)} \\\\\n",
    "\n",
    "&=\n",
    "p_{ij}(1,1)\n",
    "\\log{\\left(\\frac{p_{ij}(1,1)}{p_i(1)p_j(1)}\\right)}\n",
    "+\n",
    "p_{ij}(1,0)\n",
    "\\log{\\left(\\frac{p_{ij}(1,0)}{p_i(1)p_j(0)}\\right)}\n",
    "+\n",
    "p_{ij}(0,1)\n",
    "\\log{\\left(\\frac{p_{ij}(0,1)}{p_i(0)p_j(1)}\\right)}\n",
    "+\n",
    "p_{ij}(0,0)\n",
    "\\log{\\left(\\frac{p_{ij}(0,0)}{p_i(0)p_j(0)}\\right)} \\\\\n",
    "\n",
    "&=\n",
    "(c_{ij}/c)\n",
    "\\log{\\left(\\frac{c_{ij}/c}{(c_i / c)(c_j / c)}\\right)}\n",
    "+\n",
    "((c_i - c_{ij}) / c)\n",
    "\\log{\\left(\\frac{(c_i - c_{ij}) / c}{(c_i / c)((c - c_j) / c)}\\right)}\n",
    "+\n",
    "((c_j - c_{ij}) / c)\n",
    "\\log{\\left(\\frac{(c_j - c_{ij}) / c}{((c - c_i) / c)(c_j / c)}\\right)}\n",
    "+\n",
    "((c + c_{ij} - c_i - c_j) / c)\n",
    "\\log{\\left(\\frac{(c + c_{ij} - c_i - c_j) / c}{((c - c_i) / c)((c - c_j) / c)}\\right)} \\\\\n",
    "\n",
    "&=\n",
    "c^{-1}\\left(\n",
    "c_{ij}\\ln\\left(\\frac{cc_{ij}}{c_ic_j}\\right)\n",
    "+\n",
    "(c_i-c_{ij})\\ln\\left(\\frac{c(c_i - c_{ij})}{c_i(c - c_j)}\\right)\n",
    "+\n",
    "(c_j-c_{ij})\\ln\\left(\\frac{c(c_j - c_{ij})}{c_j(c - c_i)}\\right)\n",
    "+\n",
    "(c + c_{ij} - c_i - c_j)\\ln\\left(\\frac{c(c+c_{ij}-c_{i}-c_{j})}{(c-c_{i})(c-c{j})}\\right)\n",
    "\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = subjects.load_subject(subjects.ANDROID_BASE_TEXT_VIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_EPS = 0.35\n",
    "TEXT_MIN_PTS = 3\n",
    "ALLOW_DUP_NAMES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 text clusters with a max size of 14.\n"
     ]
    }
   ],
   "source": [
    "# ...\n",
    "entities_df = DS.entities_df()\n",
    "edges = oset((r[\"src_id\"], r[\"tgt_id\"]) for _, r in DS.deps_df().iterrows())\n",
    "\n",
    "# Create a \"name_id\" for each entity that groups targets according to their name\n",
    "# entities_df[\"name_id\"] = entities_df.groupby(\"name\").ngroup()\n",
    "\n",
    "# Cluster by name\n",
    "similarity = naming.NameSimilarity(list(DS.targets_df[\"name\"]), allow_dup_names=ALLOW_DUP_NAMES)\n",
    "clustering = DBSCAN(eps=TEXT_EPS, min_samples=TEXT_MIN_PTS, metric=\"precomputed\").fit(similarity.dist_mat)\n",
    "entities_df[\"name_cluster_id\"] = to_name_cluster_labels(entities_df, similarity, clustering.labels_)\n",
    "\n",
    "# Print cluster info\n",
    "n_clusters = max(*clustering.labels_) + 1\n",
    "max_cluster_len = sp.stats.mode([l for l in clustering.labels_ if l >= 0], keepdims=False).count\n",
    "print(\"Found {} text clusters with a max size of {}.\".format(n_clusters, max_cluster_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5367276396126864"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.sim(\"LOG_TAG\", \"logCursor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('top_pad_offset', 0.7100504102581341),\n",
       " ('total_pad_top', 0.6447012565212688),\n",
       " ('extend_pad_top', 0.6131523086266681),\n",
       " ('compound_drawabl_pad', 0.5781845830131089),\n",
       " ('fade_top', 0.5429261623597115),\n",
       " ('compound_pad_start', 0.48466408946957457),\n",
       " ('compound_pad_right', 0.47707748489327506),\n",
       " ('compound_pad_left', 0.47707748489327473),\n",
       " ('pad', 0.46324654398322196)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.most_sim(\"getCompoundPaddingTop\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>name</th>\n",
       "      <th>kind</th>\n",
       "      <th>start_row</th>\n",
       "      <th>end_row</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>492564</th>\n",
       "      <td>1323</td>\n",
       "      <td>LOG_TAG</td>\n",
       "      <td>field</td>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492565</th>\n",
       "      <td>1323</td>\n",
       "      <td>DEBUG_EXTRACT</td>\n",
       "      <td>field</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492566</th>\n",
       "      <td>1323</td>\n",
       "      <td>DEBUG_CURSOR</td>\n",
       "      <td>field</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492567</th>\n",
       "      <td>1323</td>\n",
       "      <td>TEMP_POSITION</td>\n",
       "      <td>field</td>\n",
       "      <td>372</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492568</th>\n",
       "      <td>1323</td>\n",
       "      <td>XMLTypefaceAttr</td>\n",
       "      <td>annotation</td>\n",
       "      <td>377</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289503</th>\n",
       "      <td>1323</td>\n",
       "      <td>onInputConnectionOpenedInternal</td>\n",
       "      <td>method</td>\n",
       "      <td>14211</td>\n",
       "      <td>14218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289505</th>\n",
       "      <td>1323</td>\n",
       "      <td>onInputConnectionClosedInternal</td>\n",
       "      <td>method</td>\n",
       "      <td>14221</td>\n",
       "      <td>14226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246325</th>\n",
       "      <td>1323</td>\n",
       "      <td>onReceiveContent</td>\n",
       "      <td>method</td>\n",
       "      <td>14245</td>\n",
       "      <td>14252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493175</th>\n",
       "      <td>1323</td>\n",
       "      <td>logCursor</td>\n",
       "      <td>method</td>\n",
       "      <td>14254</td>\n",
       "      <td>14260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16426</th>\n",
       "      <td>1323</td>\n",
       "      <td>onCreateViewTranslationRequest</td>\n",
       "      <td>method</td>\n",
       "      <td>14274</td>\n",
       "      <td>14308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        parent_id                             name        kind  start_row   \n",
       "id                                                                          \n",
       "492564       1323                          LOG_TAG       field        368  \\\n",
       "492565       1323                    DEBUG_EXTRACT       field        369   \n",
       "492566       1323                     DEBUG_CURSOR       field        370   \n",
       "492567       1323                    TEMP_POSITION       field        372   \n",
       "492568       1323                  XMLTypefaceAttr  annotation        377   \n",
       "...           ...                              ...         ...        ...   \n",
       "289503       1323  onInputConnectionOpenedInternal      method      14211   \n",
       "289505       1323  onInputConnectionClosedInternal      method      14221   \n",
       "246325       1323                 onReceiveContent      method      14245   \n",
       "493175       1323                        logCursor      method      14254   \n",
       "16426        1323   onCreateViewTranslationRequest      method      14274   \n",
       "\n",
       "        end_row  \n",
       "id               \n",
       "492564      368  \n",
       "492565      369  \n",
       "492566      370  \n",
       "492567      372  \n",
       "492568      379  \n",
       "...         ...  \n",
       "289503    14218  \n",
       "289505    14226  \n",
       "246325    14252  \n",
       "493175    14260  \n",
       "16426     14308  \n",
       "\n",
       "[724 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
